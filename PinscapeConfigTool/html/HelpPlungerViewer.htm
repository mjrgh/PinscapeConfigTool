<!DOCTYPE html>
<html>
<head>
   <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
   <link rel="stylesheet" href="main.css"/>
   <title>Plunger Sensor Viewer</title>
</head>
<body class="help">

<h1>
   <img style="float: right;" src="h1plunger.png">
   Plunger Sensor Viewer
   <img style="visibility: hidden; vertical-align: middle;" src="h1plunger.png">
</h1>

<div>

   <p>
      This window is designed to help you install and adjust your
      plunger sensor.  It shows the current position reading
      and the calibration data.  If you're using an imaging
      sensor (such as a TSL1410R), it shows a real-time view of
      the captured image.
   </p>

   <h2>Quadrature sensor visualization (AEDR-8300)</h2>
   <p>
      For quadrature sensors (AEDR-8300), the "snapshot"
      box displays a visualization of the bar scale that the sensor
      moves across.  Quadrature sensors don't take photographic
      images, so this is just a simulation of what we infer the
      bar scale to look like - it's not a true photo image.  What
      the sensor actually sees is essentially two side-by-side
      pixel readings, 1/150 of an inch apart.  Given that
      the white and black bars on the scale are precisely 1/150"
      wide each (or, at least, they should be, if things are
      set up properly), we can infer where we must be relative
      to the nearest two bars.  The visualization extrapolates
      that out to the rest of the nearby bars, but the sensor
      doesn't actually see those; it only sees the two bars in
      the center, in the boxes marked "A" and "B".  Those boxes
      represent the actual readings on the sensor's "A" and "B
      channels.
   </p>

   <h2>Proximity sensor visualization (VCNL4010)</h2>
   <p>
      The VCNL4010 proximity sensor doesn't actually measure
      distance; it measures the brightness of an infrared light
      beam reflected from the target (the end of the plunger).
      The amount of reflected light increases as the target gets
      closer to the sensor, which allows us to infer the distance
      from the brightness.  To help you see what's really going on
      at the physical level, the Plunger Viewer displays the
      brightness level measured on the sensor.  The yellow bar
      shows the brightness reading - this is a number from 0
      to 65535, in abstract units, with 0 meaning that the sensor
      isn't seeing any light at all and 65535 meaning that it's
      fully saturated (like an overexposed photo).  The green
      bar superimposed over that shows the distance calculation.
      Remember that the sensor doesn't actually measure distance -
      it only measures brightness - so the distance calculation is
      just the result of doing some math on the brightness.
      This is based on the calibration data, so the distance reading
      isn't meaningful until you run the calibration procedure.
      If the green distance bar is missing or erratic, try calibrating.
      If the yellow brightness bar is missing, or it doesn't respond
      as you move the plunger, the software probably isn't connected
      to the sensor properly - make sure the GPIO pin assignments are
      correct in the Settings, and check the wiring between the
      KL25Z and the sensor.
   </p>

   <h2>Imaging sensor snapshot (TSL1410R, TCD1103)</h2>
   <p>
      For imaging sensors, the "snapshot" box displays the
      image pixels that your sensor is capturing.  This is updated
      continuously, so that you can immediately see the effects of
      adjusting the sensor position or the light source.
   </p>

   <p>
      The pixels are rendered in shades of gray, since the
      sensors we support are monochromatic.  Black pixels correspond
      to full darkness (or full shadow) on the sensor, and white
      pixels are fully saturated (maximum brightness at the sensor).
      Our sensor types are one-dimensional, meaning that
      the pixel array is one pixel wide.  The display stretches
      out each pixel vertically to make it easier to visualize,
      so the image might look like a bar code or a series of
      vertical stripes.
   </p>

   <p>
      For optimal performance, adjust your sensor and light
      source as follows:
   </p>
   
   <ul>
      
      <li>Position the sensor so that the <b>shadow edge</b>
      is always in view, whether the plunger is pushed all the
      way forward or pulled all the way back.
      
      <li>The shadow edge should be sharp and narrow.
      It's easier to get a sharp edge if you use a "point
      source" - a light source with a small aperture - and
      you position it relatively far away from the plunger
      (on the floor of the cabinet, say).  The light
      source should be roughly centered under the sensor
      and pointing straight at it.
      
      <li>The light source brightness should be set so
      that there's a good degree of contrast between the
      dark and light regions in the image.  If the image
      is all black or dark gray, the light source needs
      to be brighter.  If the image is all white or
      washed out, the light source needs to be dimmer.
      
   </ul>
   
   <p>
      The statistics shown under the image give you some more
      information about the sensor scan.
   </p>

   <p>The Min and Max Brightness levels are on a scale from 0 to
      255.  0 is full darkness, 255 is fully saturated.  If your
      light source is set up properly, the Max value should be
      at least 30 or 40 higher than the Min value.  This indicates
      a good level of contrast between the lit areas and the
      shadows.
   </p>

   <h2>Image Zoom</h2>

   <p>
      For the imaging sensors that take pictures of the plunger
      (TLS1410/12, TCD1103), you can use the Zoom control to get
      a closer view of the sensor pixels.  This is especially
      helpful when adjusting the lens focus for sensors where
      that's a thing, such as the TCD1103.
   </p>
   <p>
      Use the Zoom combo box to select a zoom factor.
   </p>
   <p>
      When zoomed in, you can scroll the image snapshot by
      using the mouse to drag the snapshot area left or right.
   </p>


   <h2>Plunger position</h2>

   <p>If the controller is able to read the plunger position
      from the sensor, the position will be displayed as a
      green bar across the bottom of the snapshot box.
   </p>

   <p>
      If you don't see a green bar, it means that the controller
      can't read the position.  If you're using an imaging
      sensor, this might be because the image is too dark
      or too washed out.
   </p>

   <h2>Current calibration display</h2>

   <p>The snapshot box draws little arrows to show the current
      calibration limits.  The purple arrows show the park position,
      where the plunger sits when at rest. 
      The red arrows show the maximum retraction position.
      If the plunger is calibrated properly, the plunger
      should settle and stay roughly at the park position
      when you're not moving it.
   </p>

   <p>Real plungers always have at least a little mechanical play,
      so your plunger won't come to rest at exactly the same spot
      every time you fire it.  It should be fairly consistent,
      though.  If the park position shown isn't fairly close
      to the actual resting position, re-run the calibration
      procedure.
   </p>
      

   <h2>Calibrating</h2>

   <p>If you just installed the sensor, or you've adjusted
      its position, you should calibrate it.  You can also
      recalibrate any time if the displayed park position
      doesn't look right.
   </p>

   <p>To calibrate, make sure the plunger is at rest at its
      normal park position.  Then click the Calibrate button,
      and follow the on-screen instructions.
   </p>

   <p>Note that the pixel display is disabled during the
      calibration process.  It will resume when the
      calibration finishes.
   </p>
   

   <h2>Timing statistics</h2>

   <p>The scan time shows you how long it takes, on average,
      to take one position reading from the sensor.  For an imaging
      sensor, this is the time it takes for the sensor to snap
      a photo (so to speak) and then transfer the image pixels
      to the microcontroller.  The controller has to read the pixels
      one by one, so the pixel transfer is usually the bulk of the
      scan time for an image sensor.  For an analog sensor (an LVDT
      or potentiometer, for example), the "scan time" is simply the
      time it takes to sample the analog voltage level on the
      sensor output and turn it into a digital reading.
   </p>

   <p>The capture time for images from the TSL141R should be
      about 2.5ms with the current controller software.  That's
      about 400 frames per second, which would be considered
      pretty fast in a regular photography or video context.  A
      high frame rate is good for capturing fast motion, which
      is exactly the situation we have when you pull back and
      release the plunger.
   </p>

   <p>For non-imaging sensors, the "scan time" is usually
      negligible (tens of microseconds), since we only have to
      wait for the analog voltage sampler to take a reading.
   </p>

   <p>The "processing time" shows how long it took for the
      software to analyze the raw data for the current frame to
      determine the current plunger position.  For an imaging
      sensor, this reflects the time it takes for the software
      to analyze the image pixels.  For an analog sensor, this
      is usually zero (or close enough), since we treat the
      plunger position as linearly proportional to the voltage
      level.  In other words, the "processing" is simply a
      multiplication, which takes less than a microsecond on
      the controller's CPU.
   </p>

   <p>The timing statistics are provided mostly as a sanity
      check, to help determine if things are working as expected.
      There isn't anything you can do in the configuration to
      adjust these directly.  If the times displayed aren't in
      the right ballpark, there might be a problem with the
      software or with your setup that bears looking into.
   </p>

   <p>A couple of notes on the timing.  First, the image update
      rate that you see in the setup window will be much slower
      than what you see in the statistics.  The USB transfer to
      send the full image to the PC takes a lot longer than
      reading the image on the microcontroller.  This overhead
      doesn't apply during normal operations - the controller
      normally analyzes the pixels all by itself and never sends
      them to the PC.  So the statistics really do reflect what's
      going on in the controller, even though the viewer window
      can't display updates at the same speed.
      Second, for the TSL1410R sensor, the
      "processing time" and "scan time" happen concurrently,
      because the sensor is already snapping the next photo and
      transferring it to the controller while the controller is
      analyzing the previous one.  This means that the true frame
      rate is basically determined by the longer of the sensor
      scan time and the processing time.
   </p>


   <h2>Contrast enhancement</h2>

   <p>
	  For a pixel-based sensor, click the "Enhance contrast" checkbox
	  to exaggerate the contrast level in the displayed pixel readout.
	  This makes the display show the bright pixels brighter than they
	  really are, and the dark pixels darker than they really are.
   </p>
   <p>
	  This can be helpful when fine-tuning your sensor installation.
	  The image analysis routines on the KL25Z generally work by
	  finding the dark and light regions in the image, and the edges
	  between regions.  Exaggerating the contrast can make this
	  structure more apparent when the physical light level is relatively
	  uniform. 
   </p>
   <p>
	  Enhanced contrast is purely a display option.  It doesn't in any
	  way affect the way the readings are taken from the sensor, or how
	  the KL25Z processes the readings.  In fact, the KL25Z doesn't even
	  know you're using the enhanced contrast; the only effect is on
	  the on-screen display.
   </p>


   <h2>Full resolution and low res</h2>
   
   <p>If you're using an image sensor, the <b>Full resolution</b> and
      <b>Low resolution</b> buttons let you select how many pixels you
      want to view in the dialog.  This doesn't affect how the controller
      reads the sensor; it only affects the visualization in the dialog.
      The low res mode is offered simply to let you speed up the frame
      rate displayed in the dialog.
   </p>

   <p>The resolution setting doesn't change anything
      outside of the dialog.  It has absolutely no effect on how the
      controller reads the sensor or reports the plunger position in
      normal pinball play.  It also has no effect even within the dialog
      for non-imaging sensors.
   </p>

   <h2>Scan Mode</h2>
   <p>
      Starting with the October 2024 firmware, the TLS1410R/1412S sensors
      provide several edge-scanning algorithms that you can choose from.
      If you're running the latest firmware and you have a suitable sensor
      installed, the plunger viewer will show a drop list that lets you
      select which scan mode to use.
   </p>
   <p>
      The reason this is configurable is that it's possible that the
      performance of the algorithms will vary with different optical
      conditions, such as the type of light source and its placement.
      In other words, which algorithm is "best" might vary by setup.
      Up until the October 2024 firmware, the firmware only implemented
      one algorithm, so there was never a need to configure this before.
      The addition of the plunger speed reporting features in the
      earlier 2024 firmware revealed that the original algorithm
      performs poorly when the plunger is moving near its peak
      speed, so a couple of new algorithms were added to improve
      high-speed tracking.  In my testing, the new "Steady Slope"
      method performs best across all speed ranges, so it's now the
      default selection.  However, since this is a change from the
      very long-standing and well-tested original algorithm, I
      wanted to provide an option to switch back to the old
      algorithm in case the new one doesn't work as well on
      everyone's system as it does on my test system.  
   </p>
   <p>
      All of the algorithms have the same goal, of scanning the
      sensor image to find the edge of the shadow cast by the plunger,
      and thus determine the plunger's position across the length
      of the sensor.  Here's a brief explanation of each algorithm's
      details:
   </p>
   <ul>
      <li><b>Steady Slope:</b> This is the new default setting.  It
      detects the shadow edge position by searching for a region of
      steadily changing brightness, from bright to dark.  This
      algorithm is particularly good at adapting to different
      degrees of blur in the shadow image, both from the blurring
      in the shadow's penumbra and from motion blur when the plunger
      is moving rapidly, because it's not sensitive to how rapidly
      the brightness changes across the "slope" region.  It only
      cares that there's a steady change from bright to shadow.

      <li><b>Steepest Slope:</b> This is the original algorithm
      that's been used in the firmware for many years, so it's
      well proven.  This algorithm scans the image to find the
      location with the greatest difference in brightness between
      adjacent pixels.  This algorithm is good at identifying the
      edge when the plunger is stationary and the actual optical
      shadow edge is sharp, but it's sensitive to focus blur and
      motion blur.  Blur spreads out the edge over several pixels
      (which can turn into many pixels when the plunger is moving
      fast), which reduces the contrast across adjacent pixels.
      When the blurred region is very wide, as during fast motion,
      the brightness gradient can become so gradual that random
      pixel noise in the image can cause a greater pixel-to-pixel
      brightness difference than in the blurred region, which
      can fool the algorithm and make it pick a seemingly random
      point as the plunger location.  This was never very visible
      before the plunger speed reporting features were added,
      because such extreme motion blur only occurs very briefly,
      for about 5-10 ms at a time, during the fastest plunger
      motions.  But it became apparent with the new speed
      reporting features, where the moment-to-moment tracking
      becomes important even at those small time scales.
      <p>
         If you want to restore the same tracking behavior of
         previous versions of the firmware, select this mode.
      </p>

      <li><b>Slope Across Gap:</b>  This is a slight modification
      to the original Steepest Slope algorithm that looks for the
      greatest change in brightness across a gap, rather than
      between adjacent pixels.  The gap is intended to approximate
      the amount of blurring expected in the image, and is determined
      by extrapolating the speed from the prior two exposures to
      estimate the amount of blurring in the new image.  This
      algorithm does a better job of tracking the plunger at
      high speeds than the original Steepest Slope algorithm did,
      but it still relies on an estimate of the blurred region
      width, which reduces its precision under changing speed
      conditions.  The Steady Slope algorithm is inherently
      adaptive to the blur conditions in each frame, which I think
      makes it more accurate across different speeds and optical
      conditions.

   </ul>
      

   <h2>Jitter Filter</h2>

   <p>
	  No measuring device is perfect, including the plunger sensors.
	  All sensors have some inherent inaccuracies, which means that they
	  won't always get exactly the same reading twice in a row even when
	  the plunger itself is sitting perfectly still.
   </p>
   <p>
	  On a virtual cab, we don't merely have to take two readings in
	  a row:  we have to take readings <i>constantly</i>, tens or
	  hundreds of times per second.  We want the game to respond immediately
	  when you move the plunger, so we have to know where it is from
	  moment to moment.  With such a rapid series of readings, any
	  inaccuracies in the sensor become apparent on-screen as "jitter",
	  meaning that the virtual plunger jiggles around slightly even when
	  the real plunger is sitting perfectly still.
   </p>
   <p>
	  The "jitter filter" is a special feature in the firmware that lets
	  you filter out this type of random motion to make the on-screen
	  animation more stable and realistic.  If your on-screen plunger
	  jitters noticeably, you can use the filter to reduce this.  Some
	  sensors need this more than others, so you might not need it at all.
	  If your sensor produces stable animation without the filter,
	  you're better off keeping the filter disabled.
   </p>
   <p>
	  The filter works by setting a "window" size for random motion.  Any
	  motion within this window is ignored, so the on-screen plunger will
	  remain motionless even if the sensor readings are fluctuating within
	  the boundaries of the window.  The window size is set in terms of the
	  native units for the sensor, which are the same units shown in the
	  sensor display in the plunger viewer window.
   </p>
   <p>
	  Larger window sizes produce stronger filtering, but they also
	  reducing the usable precision of the plunger.  Use the lowest setting that
	  produces satisfactory results on your machine.  You can disable the filter
	  entirely by setting the window size to 0 (zero).
   </p>
   <p>
	  To help you set up the filter, the viewer window provides a visualization
	  of the filter and its effects.  When you enable the filter (by setting a
	  non-zero window size), the green bar at the bottom of the sensor window
	  shows the <b>filtered</b> position, which is
	  what Visual Pinball sees.  You'll also see a light green box at the end of
	  the bar; this shows you the current bounds of the filter window.  And
	  within the box, a red line shows you the <b>raw</b> position reading from
	  the sensor, before the filter was applied.
   </p>
   <p>
	  The goal is to make the filter window just big enough to contain the random
	  motion, if any, of the raw reading, shown by the red line.  With the plunger at
	  rest, start with a small filter window setting, and observe the effect for
	  a little while.  If the red line jiggles around so much that the window has
	  to keep jumping around to keep up, increase the window size slightly; repeat
	  until you find a window big enough to contain the random noise.
   </p>

</div>


</body>
</html>
